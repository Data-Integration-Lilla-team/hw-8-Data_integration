{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23681f8e",
   "metadata": {},
   "source": [
    "# Schema matching con i tool di Valentine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7b6e5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "import pandas as pd\n",
    "from valentine import valentine_match\n",
    "from valentine.algorithms import Coma, Cupid, DistributionBased, JaccardLevenMatcher, SimilarityFlooding\n",
    "import pprint\n",
    "import random\n",
    "from itertools import combinations\n",
    "import seaborn as sns\n",
    "import matplotlib.colors\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import shutil\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bfeb401",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_base_path = \"..\\\\..\\\\Dataset\\\\Clusters_CSV\\\\original\\\\\"\n",
    "plot_path = \".\\\\plot\\\\\"\n",
    "if os.path.exists(plot_path):\n",
    "    shutil.rmtree(plot_path)\n",
    "    os.mkdir(plot_path)\n",
    "else:\n",
    "    os.mkdir(plot_path)\n",
    "dictionary_path = \".\\\\dictionary\\\\\"\n",
    "if os.path.exists(dictionary_path):\n",
    "    shutil.rmtree(dictionary_path)\n",
    "    os.mkdir(dictionary_path)\n",
    "else:\n",
    "    os.mkdir(dictionary_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e4a3fa",
   "metadata": {},
   "source": [
    "### Estrazione score match fra coppie di colonne per ogni cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35120907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# res0 = {\n",
    "#     (table1, column1, table2, column2): score\n",
    "# }\n",
    "def schema_matching(df1, df2, matcher, df1_name, df2_name):\n",
    "    matches = valentine_match(df1, df2, matcher, df1_name, df2_name)\n",
    "    res0 = {}\n",
    "    res1 = []\n",
    "    for key in matches:\n",
    "        res0[(key[0][0], key[0][1], key[1][0], key[1][1])] = matches[key]    \n",
    "        res1.append([matcher.__class__.__name__, key[0][0], key[0][1], key[1][0], key[1][1], matches[key]])\n",
    "    return (res0, pd.DataFrame(res1, columns=[\"Matcher\", \"Table1\", \"Column1\", \"Table2\", \"Column2\", \"Score\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2077c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform dictionary d = {a: 1, b: [1,1], c: 2} in d = {a: [1], b: [1,1], c: [2]}\n",
    "def transform_dictionary(d):\n",
    "    for key, value in d.items(): \n",
    "        if type(d[key]) != list:\n",
    "            d[key] = [value]\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2873015d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge two dictionary d1 = {a: 1, b: [1,1], c: 3, d: 1} and d1 = {a: 2, b: [2,1], c: [2]}\n",
    "# in d3 = {a: [1,2], b: [1,1,2,1], c: [3,2], d: [1]}\n",
    "def merge_dictionary(dict_1, dict_2):\n",
    "    dict_1 = transform_dictionary(dict_1)\n",
    "    dict_2 = transform_dictionary(dict_2)\n",
    "    tmp = {**dict_1, **dict_2}\n",
    "    for key in tmp.keys():\n",
    "        if key in dict_1 and key in dict_2:\n",
    "            dict_1[key].extend(dict_2[key])\n",
    "        elif key in dict_2:\n",
    "            dict_1[key] = dict_2[key]\n",
    "    return dict_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb7bf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster_datasets = {\n",
    "#     cluster_name: {\n",
    "#         path_file_csv: group_name\n",
    "#     }\n",
    "# }\n",
    "cluster_datasets = {}\n",
    "for cluster_folder_name in os.listdir(datasets_base_path):\n",
    "    cluster_path = os.path.join(datasets_base_path, cluster_folder_name)\n",
    "    cluster_datasets[cluster_folder_name] = {}\n",
    "    for filename in os.listdir(cluster_path):\n",
    "        dataset_path = os.path.join(cluster_path, filename)\n",
    "        cluster_datasets[cluster_folder_name][dataset_path] = os.path.splitext(filename)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fcb8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster_res = \n",
    "# {\n",
    "#     cluster1: {\n",
    "#         (table1, column1, table2, column2): [scoreCupid, scoreComa, ...]\n",
    "#     }\n",
    "# }\n",
    "\n",
    "# !! RUN = about 40 minutes\n",
    "# find attribute match (score) with matcher in my_matcher_list between all pairs of dataset (csv) in each cluster\n",
    "cluster_res = {}\n",
    "my_matcher_list = [Cupid()]\n",
    "for cluster in cluster_datasets.keys():\n",
    "    cluster_files_path = cluster_datasets[cluster].keys()\n",
    "    \n",
    "    # check if cluster contains more one dataset\n",
    "    if len(cluster_files_path) > 1:\n",
    "        \n",
    "        # all pair of dataset in cluster\n",
    "        pairs_of_datasets = list(combinations(cluster_files_path, 2))\n",
    "        res = {}\n",
    "        for pair in pairs_of_datasets:\n",
    "            df1 = pd.read_csv(pair[0])\n",
    "            df2 = pd.read_csv(pair[1])\n",
    "            df1_name = cluster_datasets[cluster][pair[0]] + \"-\" + cluster\n",
    "            df2_name = cluster_datasets[cluster][pair[1]] + \"-\" + cluster\n",
    "            \n",
    "            # find score between columns of two dataset\n",
    "            for matcher in my_matcher_list:\n",
    "                print(\"Matching cluster\" + \"(\" + cluster + \")\" + \"(\" + matcher.__class__.__name__ + \"): \" + df1_name + \" / \" + df2_name)\n",
    "                res_tmp = schema_matching(df1, df2, matcher, df1_name, df2_name)[0]\n",
    "                res = merge_dictionary(res, res_tmp)\n",
    "\n",
    "        cluster_res[cluster] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863ec100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_cluster_res = \n",
    "# {\n",
    "#     cluster1: {\n",
    "#         (table1, column1, table2, column2): meanScore\n",
    "#     }\n",
    "# }\n",
    "\n",
    "# threshold ([0,1]) for mean score value\n",
    "threshold = 0.0\n",
    "mean_cluster_res = {}\n",
    "for key1, value1 in cluster_res.items():\n",
    "    match = {}\n",
    "    for key2, value2 in value1.items():\n",
    "        mean_score = sum(value2) / len(value2)\n",
    "        if mean_score > threshold:\n",
    "            match[key2] = mean_score\n",
    "    mean_cluster_res[key1] = match"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eec663b",
   "metadata": {},
   "source": [
    "### Costruzione matrice di correlazione fra coppie di colonne per ogni cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6019e217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inverted_index_cluster = \n",
    "# {\n",
    "#     cluster1: {\n",
    "#         mainToken1: [(token1, score1), (token1, score2), (token2, score1), ...]\n",
    "#     }\n",
    "# }\n",
    "\n",
    "# score is mean score of mean_cluster_res\n",
    "\n",
    "inverted_index_cluster = {}\n",
    "for cluster, dict_of_score in mean_cluster_res.items():\n",
    "    inverted_index = {}\n",
    "    for match_tuple, score in dict_of_score.items():\n",
    "        \n",
    "        if match_tuple[1] not in inverted_index.keys():\n",
    "            inverted_index[match_tuple[1]] = []\n",
    "        if match_tuple[3] not in inverted_index.keys():\n",
    "            inverted_index[match_tuple[3]] = []\n",
    "        \n",
    "        inverted_index[match_tuple[1]].append((match_tuple[3], score))\n",
    "        inverted_index[match_tuple[3]].append((match_tuple[1], score))    \n",
    "                    \n",
    "    inverted_index_cluster[cluster] = inverted_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b308d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_inverted_index_cluster = \n",
    "# {\n",
    "#     cluster1: {\n",
    "#         mainToken1: [(token1, meanScore), (token2, meanScore), ...]\n",
    "#     }\n",
    "# }\n",
    "\n",
    "mean_inverted_index_cluster = {}\n",
    "for cluster, inverted_index in inverted_index_cluster.items():\n",
    "    mean_inverted_index = {}\n",
    "    for token, index in inverted_index.items():\n",
    "        if token not in mean_inverted_index.keys():\n",
    "            mean_inverted_index[token] = []\n",
    "        for e in set([i[0] for i in index]):\n",
    "            tmp = [k[1] for k in index if k[0] == e]\n",
    "            mean_inverted_index[token].append((e, (sum(tmp) / len(tmp))))                   \n",
    "    mean_inverted_index_cluster[cluster] = mean_inverted_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee282d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dictionary(inverted_index):\n",
    "    return set(inverted_index.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6fe61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_value_from_list_of_tuples(l, t):\n",
    "    for tup in l:\n",
    "        if tup[0] == t:\n",
    "            return tup[1]\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff452e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation_matrix_cluster = \n",
    "# {\n",
    "#     cluster1: {\n",
    "#         mainToken1: {\n",
    "#             token1: score, token2: score, ...\n",
    "#         }\n",
    "#     }\n",
    "# }\n",
    "correlation_matrix_cluster = {}\n",
    "for cluster, inverted_index in mean_inverted_index_cluster.items():\n",
    "    correlation_matrix = {}\n",
    "    dictionary = make_dictionary(mean_inverted_index_cluster[cluster])    \n",
    "    for token, values in mean_inverted_index_cluster[cluster].items():\n",
    "        terms_of_token = [e[0] for e in values]\n",
    "        correlation_matrix[token] = {}\n",
    "        for term in dictionary:\n",
    "            if term not in terms_of_token:\n",
    "                correlation_matrix[token][term] = 0\n",
    "            else:\n",
    "                correlation_matrix[token][term] = get_value_from_list_of_tuples(values, term)\n",
    "    correlation_matrix_cluster[cluster] = correlation_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82354d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save correlation_matrix_cluster\n",
    "for cluster, correlation_matrix in correlation_matrix_cluster.items():\n",
    "    json_obj = json.dumps(correlation_matrix) \n",
    "    f = open(dictionary_path+cluster+\".txt\",\"w\")\n",
    "    f.write(json_obj)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "648c30bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read correlation_matrix_cluster\n",
    "correlation_matrix_cluster = {}\n",
    "for filename in os.listdir(dictionary_path):\n",
    "    file_path = os.path.join(dictionary_path, filename)\n",
    "    cluster = os.path.splitext(filename)[0]\n",
    "    file = open(file_path)\n",
    "    correlation_matrix_cluster[cluster] = json.load(file)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "891693ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_correlation(df, base_path=\".\\\\\", title=\"Matrice di correlazione\"):\n",
    "    fig, ax = plt.subplots(figsize=(20, 20))\n",
    "    title = title\n",
    "    file_name = base_path + \"\\\\\" + \"\".join(title.lower()).replace(\" \", \"_\")\n",
    "    ax.set_title(title)\n",
    "    # ax.set_xlabel(\"Token\")\n",
    "    # ax.set_ylabel(\"Token\")\n",
    "    heatmap = sns.heatmap(df, ax=ax, fmt=\".0f\",linewidths=2, cmap=\"Purples\", square=True, cbar_kws={\"shrink\": .5})\n",
    "\n",
    "    fig.savefig(file_name, bbox_inches='tight', transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dcb81675",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cluster, correlation_matrix in correlation_matrix_cluster.items():\n",
    "    df = pd.DataFrame(correlation_matrix)\n",
    "    plot_correlation(df, base_path=plot_path, title=\"Matrice di correlazione-\" + cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb76fcc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
