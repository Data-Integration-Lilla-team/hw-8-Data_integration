{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23681f8e",
   "metadata": {},
   "source": [
    "# Schema matching con i tool di Valentine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7b6e5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "import pandas as pd\n",
    "from valentine import valentine_match\n",
    "from valentine.algorithms import Coma, Cupid, DistributionBased, JaccardLevenMatcher, SimilarityFlooding\n",
    "import random\n",
    "import seaborn as sns\n",
    "import matplotlib.colors\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import shutil\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bfeb401",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_base_path = \"..\\\\..\\\\Dataset\\\\ClusterParsed\\\\\"\n",
    "info_path = \".\\\\DatasetSchemaMatch\\\\\"\n",
    "filename_synonym = \"column_sinonimi.txt\"\n",
    "dictionary_path = \".\\\\dictionary\\\\\"\n",
    "if os.path.exists(dictionary_path):\n",
    "    shutil.rmtree(dictionary_path)\n",
    "    os.mkdir(dictionary_path)\n",
    "else:\n",
    "    os.mkdir(dictionary_path)\n",
    "plot_path = \".\\\\plot\\\\\"\n",
    "if os.path.exists(plot_path):\n",
    "    shutil.rmtree(plot_path)\n",
    "    os.mkdir(plot_path)\n",
    "else:\n",
    "    os.mkdir(plot_path)\n",
    "csv_columns_path = \".\\\\columns\\\\\"\n",
    "if os.path.exists(csv_columns_path):\n",
    "    shutil.rmtree(csv_columns_path)\n",
    "    os.mkdir(csv_columns_path)\n",
    "else:\n",
    "    os.mkdir(csv_columns_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4425583d",
   "metadata": {},
   "outputs": [],
   "source": [
    "inverted_index = {}\n",
    "for cluster_folder_name in os.listdir(datasets_base_path):\n",
    "    cluster_path = os.path.join(datasets_base_path, cluster_folder_name)\n",
    "    inverted_index[cluster_folder_name] = {}\n",
    "    for filename in os.listdir(cluster_path):\n",
    "        file_path = os.path.join(cluster_path, filename)\n",
    "        df = pd.read_csv(file_path)\n",
    "        group_name = os.path.splitext(filename)[0]\n",
    "        for column in list(df.columns):\n",
    "            if column not in inverted_index[cluster_folder_name]:\n",
    "                inverted_index[cluster_folder_name][column] = []\n",
    "            inverted_index[cluster_folder_name][column].append(group_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76f70a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster_info = {\n",
    "#     cluster_name: {\n",
    "#         files: {\n",
    "#             group_name: path_file_csv\n",
    "#         }\n",
    "#         synonym: {}\n",
    "#         index: {}\n",
    "#     }\n",
    "# }\n",
    "cluster_info = {}\n",
    "\n",
    "for cluster_folder_name in os.listdir(datasets_base_path):\n",
    "    \n",
    "    cluster_info[cluster_folder_name] = {}\n",
    "    \n",
    "    cluster_path = os.path.join(datasets_base_path, cluster_folder_name)\n",
    "    cluster_info[cluster_folder_name][\"files\"] = {}\n",
    "    \n",
    "    for filename in os.listdir(cluster_path):\n",
    "        dataset_path = os.path.join(cluster_path, filename)\n",
    "        cluster_info[cluster_folder_name][\"files\"][os.path.splitext(filename)[0]] = dataset_path\n",
    "\n",
    "for cluster_folder_name in os.listdir(info_path):\n",
    "    \n",
    "    cluster_path = os.path.join(info_path, cluster_folder_name)\n",
    "    synonym_path = os.path.join(cluster_path, filename_synonym)\n",
    "    \n",
    "    with open(synonym_path) as f:\n",
    "        data = f.read()\n",
    "    tmp = re.sub('(\\w+)', '\"\\g<1>\"', data)  \n",
    "    js_synonym = json.loads(tmp)\n",
    "        \n",
    "    cluster_info[cluster_folder_name].update({\n",
    "        \"synonym\": js_synonym,\n",
    "        \"index\": inverted_index[cluster_folder_name]\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c21b62a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cluster in cluster_info.keys():\n",
    "    if len(cluster_info[cluster][\"files\"]) > 1:\n",
    "        \n",
    "        cluster_path = csv_columns_path + cluster + \"\\\\\"\n",
    "        os.mkdir(cluster_path)\n",
    "        \n",
    "        synonym = cluster_info[cluster][\"synonym\"]\n",
    "        index = cluster_info[cluster][\"index\"]\n",
    "        \n",
    "        for main_token, tokens in synonym.items():\n",
    "            \n",
    "            data_column_cluster = {}\n",
    "            \n",
    "            for token in tokens:\n",
    "                \n",
    "                filename_with_token = index[token]\n",
    "                for filename in filename_with_token:\n",
    "                    \n",
    "                    path = cluster_info[cluster][\"files\"][filename]\n",
    "                    df_tmp = pd.read_csv(path)\n",
    "                    column = df_tmp[token]\n",
    "                    data_column_cluster[filename + \"-\" + token] = column\n",
    "                    \n",
    "            df = pd.DataFrame(data_column_cluster)\n",
    "            df.to_csv(cluster_path + main_token + \".csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e4a3fa",
   "metadata": {},
   "source": [
    "### Estrazione score match fra coppie di colonne per ogni cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35120907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# res0 = {\n",
    "#     (table1, column1, table2, column2): score\n",
    "# }\n",
    "def schema_matching(df1, df2, matcher, df1_name, df2_name):\n",
    "    matches = valentine_match(df1, df2, matcher, df1_name, df2_name)\n",
    "    res0 = {}\n",
    "    res1 = []\n",
    "    for key in matches:\n",
    "        res0[(key[0][0], key[0][1], key[1][0], key[1][1])] = matches[key]    \n",
    "        res1.append([matcher.__class__.__name__, key[0][0], key[0][1], key[1][0], key[1][1], matches[key]])\n",
    "    return (res0, pd.DataFrame(res1, columns=[\"Matcher\", \"Table1\", \"Column1\", \"Table2\", \"Column2\", \"Score\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2077c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform dictionary d = {a: 1, b: [1,1], c: 2} in d = {a: [1], b: [1,1], c: [2]}\n",
    "def transform_dictionary(d):\n",
    "    for key, value in d.items(): \n",
    "        if type(d[key]) != list:\n",
    "            d[key] = [value]\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2873015d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge two dictionary d1 = {a: 1, b: [1,1], c: 3, d: 1} and d1 = {a: 2, b: [2,1], c: [2]}\n",
    "# in d3 = {a: [1,2], b: [1,1,2,1], c: [3,2], d: [1]}\n",
    "def merge_dictionary(dict_1, dict_2):\n",
    "    dict_1 = transform_dictionary(dict_1)\n",
    "    dict_2 = transform_dictionary(dict_2)\n",
    "    tmp = {**dict_1, **dict_2}\n",
    "    for key in tmp.keys():\n",
    "        if key in dict_1 and key in dict_2:\n",
    "            dict_1[key].extend(dict_2[key])\n",
    "        elif key in dict_2:\n",
    "            dict_1[key] = dict_2[key]\n",
    "    return dict_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6fb7bf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster_datasets = {\n",
    "#     cluster_name: [list_of_path]\n",
    "# }\n",
    "cluster_datasets = {}\n",
    "for cluster_folder_name in os.listdir(csv_columns_path):\n",
    "    cluster_path = os.path.join(csv_columns_path, cluster_folder_name)\n",
    "    cluster_datasets[cluster_folder_name] = []\n",
    "    for filename in os.listdir(cluster_path):\n",
    "        dataset_path = os.path.join(cluster_path, filename)\n",
    "        cluster_datasets[cluster_folder_name].append(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fcb8fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching cluster(cbinsights)(JaccardLevenMatcher): .\\columns\\cbinsights\\city.csv\n",
      "Matching cluster(cbinsights)(JaccardLevenMatcher): .\\columns\\cbinsights\\company.csv\n",
      "Matching cluster(cbinsights)(JaccardLevenMatcher): .\\columns\\cbinsights\\country.csv\n",
      "Matching cluster(cbinsights)(JaccardLevenMatcher): .\\columns\\cbinsights\\datejoined.csv\n",
      "Matching cluster(cbinsights)(JaccardLevenMatcher): .\\columns\\cbinsights\\founded.csv\n",
      "Matching cluster(cbinsights)(JaccardLevenMatcher): .\\columns\\cbinsights\\industry.csv\n",
      "Matching cluster(cbinsights)(JaccardLevenMatcher): .\\columns\\cbinsights\\investors.csv\n",
      "Matching cluster(cbinsights)(JaccardLevenMatcher): .\\columns\\cbinsights\\name.csv\n",
      "Matching cluster(cbinsights)(JaccardLevenMatcher): .\\columns\\cbinsights\\selectinvestors.csv\n",
      "Matching cluster(cbinsights)(JaccardLevenMatcher): .\\columns\\cbinsights\\stage.csv\n",
      "Matching cluster(cbinsights)(JaccardLevenMatcher): .\\columns\\cbinsights\\totalraised.csv\n",
      "Matching cluster(cbinsights)(JaccardLevenMatcher): .\\columns\\cbinsights\\valuation.csv\n",
      "Matching cluster(companiesmarketcap)(JaccardLevenMatcher): .\\columns\\companiesmarketcap\\categories.csv\n",
      "Matching cluster(companiesmarketcap)(JaccardLevenMatcher): .\\columns\\companiesmarketcap\\change1d.csv\n",
      "Matching cluster(companiesmarketcap)(JaccardLevenMatcher): .\\columns\\companiesmarketcap\\change1y.csv\n",
      "Matching cluster(companiesmarketcap)(JaccardLevenMatcher): .\\columns\\companiesmarketcap\\change_1day.csv\n",
      "Matching cluster(companiesmarketcap)(JaccardLevenMatcher): .\\columns\\companiesmarketcap\\change_1year.csv\n",
      "Matching cluster(companiesmarketcap)(JaccardLevenMatcher): .\\columns\\companiesmarketcap\\change_1_day.csv\n",
      "Matching cluster(companiesmarketcap)(JaccardLevenMatcher): .\\columns\\companiesmarketcap\\change_1_year.csv\n",
      "Matching cluster(companiesmarketcap)(JaccardLevenMatcher): .\\columns\\companiesmarketcap\\code.csv\n",
      "Matching cluster(companiesmarketcap)(JaccardLevenMatcher): .\\columns\\companiesmarketcap\\codice.csv\n",
      "Matching cluster(companiesmarketcap)(JaccardLevenMatcher): .\\columns\\companiesmarketcap\\company_code.csv\n",
      "Matching cluster(companiesmarketcap)(JaccardLevenMatcher): .\\columns\\companiesmarketcap\\country.csv\n",
      "Matching cluster(companiesmarketcap)(JaccardLevenMatcher): .\\columns\\companiesmarketcap\\earnings.csv\n",
      "Matching cluster(companiesmarketcap)(JaccardLevenMatcher): .\\columns\\companiesmarketcap\\employees.csv\n",
      "Matching cluster(companiesmarketcap)(JaccardLevenMatcher): .\\columns\\companiesmarketcap\\id.csv\n",
      "Matching cluster(companiesmarketcap)(JaccardLevenMatcher): .\\columns\\companiesmarketcap\\marketcap.csv\n",
      "Matching cluster(companiesmarketcap)(JaccardLevenMatcher): .\\columns\\companiesmarketcap\\market_cap.csv\n",
      "Matching cluster(companiesmarketcap)(JaccardLevenMatcher): .\\columns\\companiesmarketcap\\market_capitalization_usd.csv\n",
      "Matching cluster(companiesmarketcap)(JaccardLevenMatcher): .\\columns\\companiesmarketcap\\master_cap.csv\n",
      "Matching cluster(companiesmarketcap)(JaccardLevenMatcher): .\\columns\\companiesmarketcap\\name.csv\n",
      "Matching cluster(companiesmarketcap)(JaccardLevenMatcher): .\\columns\\companiesmarketcap\\price.csv\n",
      "Matching cluster(companiesmarketcap)(JaccardLevenMatcher): .\\columns\\companiesmarketcap\\pricecap.csv\n",
      "Matching cluster(companiesmarketcap)(JaccardLevenMatcher): .\\columns\\companiesmarketcap\\rank.csv\n",
      "Matching cluster(companiesmarketcap)(JaccardLevenMatcher): .\\columns\\companiesmarketcap\\revenue.csv\n",
      "Matching cluster(companiesmarketcap)(JaccardLevenMatcher): .\\columns\\companiesmarketcap\\shareprice.csv\n",
      "Matching cluster(companiesmarketcap)(JaccardLevenMatcher): .\\columns\\companiesmarketcap\\shares.csv\n",
      "Matching cluster(companiesmarketcap)(JaccardLevenMatcher): .\\columns\\companiesmarketcap\\share_price.csv\n",
      "Matching cluster(companiesmarketcap)(JaccardLevenMatcher): .\\columns\\companiesmarketcap\\symbol.csv\n",
      "Matching cluster(companiesmarketcap)(JaccardLevenMatcher): .\\columns\\companiesmarketcap\\url.csv\n",
      "Matching cluster(disfold)(JaccardLevenMatcher): .\\columns\\disfold\\categories.csv\n",
      "Matching cluster(disfold)(JaccardLevenMatcher): .\\columns\\disfold\\ceo.csv\n",
      "Matching cluster(disfold)(JaccardLevenMatcher): .\\columns\\disfold\\code.csv\n",
      "Matching cluster(disfold)(JaccardLevenMatcher): .\\columns\\disfold\\country.csv\n",
      "Matching cluster(disfold)(JaccardLevenMatcher): .\\columns\\disfold\\employees.csv\n",
      "Matching cluster(disfold)(JaccardLevenMatcher): .\\columns\\disfold\\founded.csv\n",
      "Matching cluster(disfold)(JaccardLevenMatcher): .\\columns\\disfold\\gbp.csv\n",
      "Matching cluster(disfold)(JaccardLevenMatcher): .\\columns\\disfold\\headquarters.csv\n",
      "Matching cluster(disfold)(JaccardLevenMatcher): .\\columns\\disfold\\headquarters_continent.csv\n",
      "Matching cluster(disfold)(JaccardLevenMatcher): .\\columns\\disfold\\headquarters_country.csv\n",
      "Matching cluster(disfold)(JaccardLevenMatcher): .\\columns\\disfold\\id.csv\n",
      "Matching cluster(disfold)(JaccardLevenMatcher): .\\columns\\disfold\\industry.csv\n",
      "Matching cluster(disfold)(JaccardLevenMatcher): .\\columns\\disfold\\link.csv\n",
      "Matching cluster(disfold)(JaccardLevenMatcher): .\\columns\\disfold\\marketcap.csv\n",
      "Matching cluster(disfold)(JaccardLevenMatcher): .\\columns\\disfold\\market_cap.csv\n"
     ]
    }
   ],
   "source": [
    "# !! RUN = about 40 minutes\n",
    "cluster_res = {}\n",
    "my_matcher_list = [JaccardLevenMatcher()] # DistributionBased() JaccardLevenMatcher()\n",
    "for cluster, paths in cluster_datasets.items():\n",
    "    \n",
    "    res = {}\n",
    "    for path in paths:\n",
    "        \n",
    "        df1 = pd.read_csv(path)\n",
    "        df2 = pd.read_csv(path)\n",
    "\n",
    "        for matcher in my_matcher_list:\n",
    "            print(\"Matching cluster\" + \"(\" + cluster + \")\" + \"(\" + matcher.__class__.__name__ + \"): \" + path)\n",
    "            res_tmp = schema_matching(df1, df2, matcher, \"table1\", \"table2\")[0]\n",
    "            res = merge_dictionary(res, res_tmp)\n",
    "        \n",
    "    cluster_res[cluster] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "863ec100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_cluster_res = \n",
    "# {\n",
    "#     cluster1: {\n",
    "#         (table1, column1, table2, column2): meanScore\n",
    "#     }\n",
    "# }\n",
    "\n",
    "# threshold ([0,1]) for mean score value\n",
    "threshold = 0.0\n",
    "mean_cluster_res = {}\n",
    "for key1, value1 in cluster_res.items():\n",
    "    match = {}\n",
    "    for key2, value2 in value1.items():\n",
    "        mean_score = sum(value2) / len(value2)\n",
    "        if mean_score > threshold:\n",
    "            match[key2] = mean_score\n",
    "    mean_cluster_res[key1] = match"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eec663b",
   "metadata": {},
   "source": [
    "### Costruzione matrice di correlazione fra coppie di colonne per ogni cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6019e217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inverted_index_cluster = \n",
    "# {\n",
    "#     cluster1: {\n",
    "#         mainToken1: [(token1, score1), (token1, score2), (token2, score1), ...]\n",
    "#     }\n",
    "# }\n",
    "\n",
    "# score is mean score of mean_cluster_res\n",
    "\n",
    "inverted_index_cluster = {}\n",
    "for cluster, dict_of_score in mean_cluster_res.items():\n",
    "    inverted_index = {}\n",
    "    for match_tuple, score in dict_of_score.items():\n",
    "        \n",
    "        if match_tuple[1] not in inverted_index.keys():\n",
    "            inverted_index[match_tuple[1]] = []\n",
    "        if match_tuple[3] not in inverted_index.keys():\n",
    "            inverted_index[match_tuple[3]] = []\n",
    "        \n",
    "        inverted_index[match_tuple[1]].append((match_tuple[3], score))\n",
    "        inverted_index[match_tuple[3]].append((match_tuple[1], score))    \n",
    "                    \n",
    "    inverted_index_cluster[cluster] = inverted_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b308d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_inverted_index_cluster = \n",
    "# {\n",
    "#     cluster1: {\n",
    "#         mainToken1: [(token1, meanScore), (token2, meanScore), ...]\n",
    "#     }\n",
    "# }\n",
    "\n",
    "mean_inverted_index_cluster = {}\n",
    "for cluster, inverted_index in inverted_index_cluster.items():\n",
    "    mean_inverted_index = {}\n",
    "    for token, index in inverted_index.items():\n",
    "        if token not in mean_inverted_index.keys():\n",
    "            mean_inverted_index[token] = []\n",
    "        for e in set([i[0] for i in index]):\n",
    "            tmp = [k[1] for k in index if k[0] == e]\n",
    "            mean_inverted_index[token].append((e, (sum(tmp) / len(tmp))))                   \n",
    "    mean_inverted_index_cluster[cluster] = mean_inverted_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee282d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dictionary(inverted_index):\n",
    "    return set(inverted_index.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a6fe61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_value_from_list_of_tuples(l, t):\n",
    "    for tup in l:\n",
    "        if tup[0] == t:\n",
    "            return tup[1]\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4ff452e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation_matrix_cluster = \n",
    "# {\n",
    "#     cluster1: {\n",
    "#         mainToken1: {\n",
    "#             token1: score, token2: score, ...\n",
    "#         }\n",
    "#     }\n",
    "# }\n",
    "correlation_matrix_cluster = {}\n",
    "for cluster, inverted_index in mean_inverted_index_cluster.items():\n",
    "    correlation_matrix = {}\n",
    "    dictionary = make_dictionary(mean_inverted_index_cluster[cluster])    \n",
    "    for token, values in mean_inverted_index_cluster[cluster].items():\n",
    "        terms_of_token = [e[0] for e in values]\n",
    "        correlation_matrix[token] = {}\n",
    "        for term in dictionary:\n",
    "            if term not in terms_of_token:\n",
    "                correlation_matrix[token][term] = 0\n",
    "            else:\n",
    "                correlation_matrix[token][term] = get_value_from_list_of_tuples(values, term)\n",
    "    correlation_matrix_cluster[cluster] = correlation_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a82354d8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dictionary_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-a7b4f6043499>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcluster\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorrelation_matrix\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcorrelation_matrix_cluster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mjson_obj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorrelation_matrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdictionary_path\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mcluster\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\".txt\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"w\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjson_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dictionary_path' is not defined"
     ]
    }
   ],
   "source": [
    "# save correlation_matrix_cluster\n",
    "for cluster, correlation_matrix in correlation_matrix_cluster.items():\n",
    "    json_obj = json.dumps(correlation_matrix) \n",
    "    f = open(dictionary_path+cluster+\".txt\",\"w\")\n",
    "    f.write(json_obj)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648c30bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read correlation_matrix_cluster\n",
    "correlation_matrix_cluster = {}\n",
    "for filename in os.listdir(dictionary_path):\n",
    "    file_path = os.path.join(dictionary_path, filename)\n",
    "    cluster = os.path.splitext(filename)[0]\n",
    "    file = open(file_path)\n",
    "    correlation_matrix_cluster[cluster] = json.load(file)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891693ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_correlation(df, base_path=\".\\\\\", title=\"Matrice di correlazione\"):\n",
    "    fig, ax = plt.subplots(figsize=(20, 20))\n",
    "    title = title\n",
    "    file_name = base_path + \"\\\\\" + \"\".join(title.lower()).replace(\" \", \"_\")\n",
    "    ax.set_title(title)\n",
    "    # ax.set_xlabel(\"Token\")\n",
    "    # ax.set_ylabel(\"Token\")\n",
    "    heatmap = sns.heatmap(df, ax=ax, fmt=\".0f\", linewidths=2, cmap=\"Purples\", square=True, cbar_kws={\"shrink\": .5})\n",
    "\n",
    "    fig.savefig(file_name, bbox_inches='tight', transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb81675",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cluster, correlation_matrix in correlation_matrix_cluster.items():\n",
    "    df = pd.DataFrame(correlation_matrix)\n",
    "    plot_correlation(df, base_path=plot_path, title=\"Matrice di correlazione-\" + cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb76fcc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
