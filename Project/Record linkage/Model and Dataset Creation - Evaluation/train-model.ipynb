{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deepmatcher as dm\n",
    "import py_entitymatching as em\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py_entitymatching.io.parsers:Metadata file is not present in the given path; proceeding to read the csv file.\n",
      "WARNING:py_entitymatching.catalog.catalog_manager:Attribute (id ) does not qualify  to be a key; Not setting/replacing the key\n",
      "WARNING:py_entitymatching.io.parsers:Metadata file is not present in the given path; proceeding to read the csv file.\n",
      "WARNING:py_entitymatching.catalog.catalog_manager:Attribute (id ) does not qualify  to be a key; Not setting/replacing the key\n"
     ]
    }
   ],
   "source": [
    "A = em.read_csv_metadata(r\"C:\\hw-8-Data_integration\\Project\\Record linkage\\idea_final_schema.csv\", key='id', low_memory = False)\n",
    "B = em.read_csv_metadata(r\"C:\\hw-8-Data_integration\\Project\\Record linkage\\idea_final_schema.csv\", key='id', low_memory = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py_entitymatching.io.parsers:Metadata file is not present in the given path; proceeding to read the csv file.\n",
      "WARNING:py_entitymatching.catalog.catalog_manager:Attribute (_id ) does not qualify  to be a key; Not setting/replacing the key\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labeled pairs: 1300\n"
     ]
    }
   ],
   "source": [
    "# Load the labeled data into a dataframe.\n",
    "G = em.read_csv_metadata(r\"C:\\hw-8-Data_integration\\Project\\Record linkage\\DATASETS\\dataset.csv\", \n",
    "                         key='_id',\n",
    "                         ltable=A, rtable=B, \n",
    "                         fk_ltable='ltable_id', fk_rtable='rtable_id')\n",
    "print('Number of labeled pairs:', len(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split labeled data into train, valid, and test csv files to disk, with the split ratio of 3:1:1.\n",
    "dm.data.split(G, r\"C:\\hw-8-Data_integration\\Project\\Record linkage\\DATASETS\\Split\", 'train.csv', 'valid.csv', 'test.csv',\n",
    "              [3, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading and processing data from \"C:\\hw-8-Data_integration\\Project\\Record linkage\\DATASETS\\Split\\train.csv\"\n",
      "0% [############################# ] 100% | ETA: 00:00:00\n",
      "Reading and processing data from \"C:\\hw-8-Data_integration\\Project\\Record linkage\\DATASETS\\Split\\valid.csv\"\n",
      "0% [############################# ] 100% | ETA: 00:00:00\n",
      "Reading and processing data from \"C:\\hw-8-Data_integration\\Project\\Record linkage\\DATASETS\\Split\\test.csv\"\n",
      "0% [############################# ] 100% | ETA: 00:00:00Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "\n",
      "Building vocabulary\n",
      "0% [#] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:00\n",
      "\n",
      "Computing principal components\n",
      "0% [#] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:01\n"
     ]
    }
   ],
   "source": [
    "# Load the training data files from the disk. Ignore the \"left_id\" and \"right_id\" \n",
    "# columns for data preprocessing.\n",
    "# The 'use_magellan_convention' parameter asks deepmatcher to use Magellan's \n",
    "# naming convention for the left and right table column name prefixes \n",
    "# (\"ltable_\", and \"rtable_\"), and also to consider \"_id\" as the ID column.\n",
    "train, validation, test = dm.data.process(\n",
    "    path=r'C:\\hw-8-Data_integration\\Project\\Record linkage\\DATASETS\\Split',\n",
    "    cache='train_cache.pth',\n",
    "    train='train.csv',\n",
    "    validation='valid.csv',\n",
    "    test='test.csv',\n",
    "    use_magellan_convention=True,\n",
    "    ignore_columns=('ltable_id', 'rtable_id'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a hybrid model.\n",
    "model = dm.MatchingModel(attr_summarizer='hybrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rocci\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py:949: UserWarning: Using non-full backward hooks on a Module that does not take as input a single Tensor or a tuple of Tensors is deprecated and will be removed in future versions. This hook will be missing some of the grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using non-full backward hooks on a Module that does not take as input a \"\n",
      "c:\\Users\\rocci\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Number of trainable parameters: 28742815\n",
      "===>  TRAIN Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rocci\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py:939: UserWarning: Using non-full backward hooks on a Module that does not return a single Tensor or a tuple of Tensors is deprecated and will be removed in future versions. This hook will be missing some of the grad_output. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using non-full backward hooks on a Module that does not return a \"\n",
      "c:\\Users\\rocci\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\functional.py:2741: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\n",
      "0% [█████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:01:13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 1 || Run Time:   79.1 | Load Time:    0.6 || F1:  72.46 | Prec:  57.36 | Rec:  98.33 || Ex/s:   9.79\n",
      "\n",
      "===>  EVAL Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [███] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 1 || Run Time:    9.2 | Load Time:    0.2 || F1:  79.08 | Prec:  66.35 | Rec:  97.87 || Ex/s:  27.80\n",
      "\n",
      "* Best F1: tensor(79.0831)\n",
      "Saving best model...\n",
      "Done.\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [█████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:01:01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 2 || Run Time:   67.0 | Load Time:    0.6 || F1:  80.73 | Prec:  70.05 | Rec:  95.24 || Ex/s:  11.54\n",
      "\n",
      "===>  EVAL Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [███] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 2 || Run Time:    8.8 | Load Time:    0.2 || F1:  81.62 | Prec:  72.78 | Rec:  92.91 || Ex/s:  29.00\n",
      "\n",
      "* Best F1: tensor(81.6199)\n",
      "Saving best model...\n",
      "Done.\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [█████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:01:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 3 || Run Time:   66.4 | Load Time:    0.6 || F1:  83.28 | Prec:  73.15 | Rec:  96.67 || Ex/s:  11.65\n",
      "\n",
      "===>  EVAL Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [███] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 3 || Run Time:    8.9 | Load Time:    0.2 || F1:  83.44 | Prec:  75.72 | Rec:  92.91 || Ex/s:  28.52\n",
      "\n",
      "* Best F1: tensor(83.4395)\n",
      "Saving best model...\n",
      "Done.\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [█████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:01:01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 4 || Run Time:   67.3 | Load Time:    0.6 || F1:  87.49 | Prec:  79.42 | Rec:  97.38 || Ex/s:  11.49\n",
      "\n",
      "===>  EVAL Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [███] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 4 || Run Time:    9.0 | Load Time:    0.2 || F1:  85.81 | Prec:  80.25 | Rec:  92.20 || Ex/s:  28.27\n",
      "\n",
      "* Best F1: tensor(85.8086)\n",
      "Saving best model...\n",
      "Done.\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [█████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:01:02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 5 || Run Time:   68.0 | Load Time:    0.6 || F1:  93.17 | Prec:  87.95 | Rec:  99.05 || Ex/s:  11.37\n",
      "\n",
      "===>  EVAL Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [███] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 5 || Run Time:    8.8 | Load Time:    0.2 || F1:  87.63 | Prec:  82.91 | Rec:  92.91 || Ex/s:  28.91\n",
      "\n",
      "* Best F1: tensor(87.6254)\n",
      "Saving best model...\n",
      "Done.\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [█████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:01:05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 6 || Run Time:   71.4 | Load Time:    0.6 || F1:  95.75 | Prec:  92.46 | Rec:  99.29 || Ex/s:  10.84\n",
      "\n",
      "===>  EVAL Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [███] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 6 || Run Time:    9.3 | Load Time:    0.2 || F1:  85.25 | Prec:  79.27 | Rec:  92.20 || Ex/s:  27.26\n",
      "\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [█████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:01:22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 7 || Run Time:   88.2 | Load Time:    0.7 || F1:  97.78 | Prec:  96.09 | Rec:  99.52 || Ex/s:   8.77\n",
      "\n",
      "===>  EVAL Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [███] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 7 || Run Time:    9.6 | Load Time:    0.2 || F1:  86.67 | Prec:  81.76 | Rec:  92.20 || Ex/s:  26.50\n",
      "\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [█████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:01:09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 8 || Run Time:   75.5 | Load Time:    0.6 || F1:  98.12 | Prec:  96.98 | Rec:  99.29 || Ex/s:  10.26\n",
      "\n",
      "===>  EVAL Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [███] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 8 || Run Time:    9.0 | Load Time:    0.2 || F1:  87.97 | Prec:  85.33 | Rec:  90.78 || Ex/s:  28.40\n",
      "\n",
      "* Best F1: tensor(87.9725)\n",
      "Saving best model...\n",
      "Done.\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [█████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:01:04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 9 || Run Time:   70.7 | Load Time:    0.6 || F1:  98.93 | Prec:  98.35 | Rec:  99.52 || Ex/s:  10.94\n",
      "\n",
      "===>  EVAL Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [███] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 9 || Run Time:    9.2 | Load Time:    0.2 || F1:  87.67 | Prec:  84.77 | Rec:  90.78 || Ex/s:  27.71\n",
      "\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [█████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:01:03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 10 || Run Time:   69.6 | Load Time:    0.5 || F1:  99.29 | Prec:  98.82 | Rec:  99.76 || Ex/s:  11.12\n",
      "\n",
      "===>  EVAL Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [███] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 10 || Run Time:    8.8 | Load Time:    0.2 || F1:  87.46 | Prec:  83.77 | Rec:  91.49 || Ex/s:  29.05\n",
      "\n",
      "---------------------\n",
      "\n",
      "Loading best model...\n",
      "Training done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(87.9725)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the hybrid model with 10 training epochs, batch size of 16, positive-to-negative \n",
    "# ratio to be 3. We save the best model (with the \n",
    "# highest F1 score on the validation set) to 'hybrid_model.pth'.\n",
    "model.run_train(\n",
    "    train,\n",
    "    validation,\n",
    "    epochs=10,\n",
    "    batch_size=16,\n",
    "    best_save_path='hybrid_model.pth',\n",
    "    pos_neg_ratio=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===>  EVAL Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rocci\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py:949: UserWarning: Using non-full backward hooks on a Module that does not take as input a single Tensor or a tuple of Tensors is deprecated and will be removed in future versions. This hook will be missing some of the grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using non-full backward hooks on a Module that does not take as input a \"\n",
      "c:\\Users\\rocci\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "c:\\Users\\rocci\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py:939: UserWarning: Using non-full backward hooks on a Module that does not return a single Tensor or a tuple of Tensors is deprecated and will be removed in future versions. This hook will be missing some of the grad_output. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using non-full backward hooks on a Module that does not return a \"\n",
      "0% [█] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 8 || Run Time:    8.0 | Load Time:    0.2 || F1:  87.91 | Prec:  86.33 | Rec:  89.55 || Ex/s:  31.55\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(87.9121)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the accuracy on the test data.\n",
    "model.run_eval(test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cce4aedea141590d780d12e6a6605bcad0d3b081bf5f576575370614619b4c61"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
